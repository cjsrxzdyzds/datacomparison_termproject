\section{Discussion}
\label{sec:discussion}

\subsection{Compression-Complexity Trade-off}
% Analyze the fundamental trade-off
Our results reveal a clear trade-off between compression performance and computational complexity. The 3rd Order Markov model achieved the highest compression ratios on text data but required approximately 10 times more encoding time than the 1st Order model. Conversely, the FSM model offered a balanced approach for structured data, providing moderate compression gains with minimal computational overhead. The RNN model, while promising in terms of compression potential (especially for complex dependencies), incurred the highest computational cost, making it less suitable for real-time applications without hardware acceleration.

\subsubsection{Model Complexity vs. Compression Gain}
Higher-order models generally achieve better compression, but with diminishing returns. For instance, moving from a 1st Order to a 2nd Order Markov model on the `alice29.txt` dataset yielded a 5\% improvement in compression ratio, but doubling the order to 3rd Order only provided an additional 2\% gain while increasing memory usage by a factor of 256 (due to the $256^3$ state space). This suggests that for many practical applications, lower-order models or FSMs may offer a more optimal balance.

\subsubsection{Practical Implications}
For applications with:
\begin{itemize}
    \item \textbf{Limited CPU}: First-order Markov or FSM models provide good balance
    \item \textbf{High compression priority}: Third-order Markov or neural models
    \item \textbf{Real-time requirements}: FSM models with specialized state machines
\end{itemize}

\subsection{Data Type Characteristics}

\subsubsection{Text vs. Binary Data}
Text data shows strong local correlations that are well-captured by Markov models, as evidenced by the superior performance of the 3rd Order model on the Canterbury Corpus text files. Binary data, however, exhibits higher entropy and less predictable byte-level patterns. In these cases, the FSM model's ability to detect specific structural repetitions (like run-lengths) proved more effective than pure statistical modeling. This suggests that domain-specific knowledge (e.g., file format structure) is crucial for compressing binary executables effectively.

\subsubsection{Structured Sequences}
DNA and protein sequences benefit significantly from higher-order Markov models due to the biological constraints that govern sequence formation (e.g., codon triplets). Our experiments showed that the 3rd Order Markov model outperformed others on the `sum` and `ptt5` datasets, likely capturing these inherent structural dependencies.

\subsection{Model Selection Guidelines}
Based on our experiments, we recommend:

\begin{table}[h]
\centering
\begin{tabular}{|l|l|l|}
\hline
\textbf{Data Type} & \textbf{Priority} & \textbf{Recommended Model} \\ \hline
Text & Speed & 1st order Markov \\ \hline
Text & Compression & LSTM \\ \hline
Binary & Balanced & FSM \\ \hline
Binary & Compression & LSTM \\ \hline
DNA & Compression & 2nd order Markov \\ \hline
General & Adaptive & LSTM (if resources allow) \\ \hline
\end{tabular}
\caption{Model selection guidelines based on data type and priority.}
\label{tab:guidelines}
\end{table}

\subsection{Limitations}

\subsubsection{Implementation Constraints}
Our MATLAB implementation may not reflect optimized C/C++ performance. [Discuss impact]

\subsubsection{Dataset Coverage}
While we tested diverse data types, [limitations in scope].

\subsubsection{Neural Model Training}
Online training of neural models during compression presents challenges: [discuss challenges and how they were addressed].

\subsection{Future Work}
Promising directions for future research include:
\begin{itemize}
    \item Hybrid models combining Markov and neural approaches
    \item Context mixing techniques to leverage multiple models
    \item Hardware acceleration for neural probability models
    \item Adaptive model selection that switches based on data characteristics
\end{itemize}
