\subsection{Compression Performance}

\subsubsection{Text Data}
% Table comparing compression ratios for text data
\begin{table}[h]
\centering
\input{tables/text_compression}
\caption{Compression ratios for text data. Lower is better.}
\label{tab:text_compression}
\end{table}

% Analysis of text results
% Analysis of text results
Figure~\ref{fig:compression_performance} compares the compression efficiency (bits per symbol) across different models.
The \textbf{LSTM model} achieved the best compression on text data, demonstrating the effectiveness of neural context modeling.
The 3rd Order Markov model struggled with data sparsity, performing worse than the LSTM and FSM on average.
The FSM model showed robust performance across all data types, particularly for its low complexity.

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{images/compression_performance.png}
\caption{Compression performance (Bits Per Symbol) across different models and datasets.}
\label{fig:compression_performance}
\end{figure}

\subsubsection{Binary Data}
% Similar structure for binary data
\begin{table}[h]
\centering
\input{tables/binary_compression}
\caption{Compression ratios for binary data.}
\label{tab:binary_compression}
\end{table}

\subsubsection{Structured Sequences}
% DNA and protein sequence results
\begin{table}[h]
\centering
\input{tables/sequence_compression}
\caption{Compression ratios for DNA and protein sequences.}
\label{tab:sequence_compression}
\end{table}
