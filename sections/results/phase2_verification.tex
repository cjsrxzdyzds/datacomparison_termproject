\subsection{Phase 2 Verification}
We extended our verification to the advanced probability models implemented in Phase 2: 3rd Order Markov, Finite State Machine (FSM), and Recurrent Neural Network (RNN).

\subsubsection{High-Order Markov and RNN Models}
We tested the 3rd Order Markov and RNN models on the same test string as Phase 1.

\begin{table}[h]
\centering
\begin{tabular}{lccc}
\toprule
\textbf{Model} & \textbf{Original Bits} & \textbf{Compressed Bits} & \textbf{Bits Per Symbol} \\
\midrule
3rd Order Markov & 456 & 457 & 8.02 \\
RNN (Simple SRN) & 456 & 443 & 7.77 \\
\bottomrule
\end{tabular}
\caption{Phase 2 verification results on a 57-byte test string.}
\label{tab:phase2_verification}
\end{table}

The RNN model achieved the best compression ratio (7.77 bps) among all models on this short string, demonstrating its ability to quickly adapt even with limited data. The 3rd Order Markov model performed slightly worse (8.02 bps), which is expected as the context dilution problem is more pronounced with higher orders on short sequences.

\subsubsection{FSM Model (Run-Length)}
To verify the FSM model's ability to handle run-length sequences, we tested it on a synthetic string containing repeated characters ("AAAAABBBBB...").

\begin{table}[h]
\centering
\begin{tabular}{lccc}
\toprule
\textbf{Model} & \textbf{Original Bits} & \textbf{Compressed Bits} & \textbf{Bits Per Symbol} \\
\midrule
FSM Model & 240 & 226 & 7.53 \\
\bottomrule
\end{tabular}
\caption{FSM verification on a run-length sequence (30 symbols).}
\label{tab:fsm_verification}
\end{table}

The FSM model successfully compressed the run-length sequence to 7.53 bits/symbol, confirming its effectiveness in detecting and exploiting repeated patterns.
